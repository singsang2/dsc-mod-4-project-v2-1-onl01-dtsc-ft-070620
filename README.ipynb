{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Repository Contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T20:33:42.170513Z",
     "start_time": "2020-11-10T20:33:42.166583Z"
    }
   },
   "source": [
    "- **Jupyter Notebook**: This notebook, <a href=\"https://github.com/singsang2/dsc-mod-4-project-v2-1-onl01-dtsc-ft-070620/blob/master/Tweet_sentiment_analysis.ipynb\">Tweet_sentiment_analysis.ipynb</a>, has Twitter sentiment analysis.\n",
    "\n",
    "- **Presentation**: This <a href=\"https://github.com/singsang2/dsc-mod-4-project-v2-1-onl01-dtsc-ft-070620/blob/master/Tweet_sentiment_analysis.pptx\">presentation</a> contains an \"Executive Summary\" that gives a brief overview of your problem/dataset, and each step of the data science process.\n",
    "\n",
    "- **Datasets**: This <a href=\"https://github.com/singsang2/dsc-mod-4-project-v2-1-onl01-dtsc-ft-070620/tree/master/datasets\">folder</a> contains all the datasets used in this project.\n",
    "\n",
    "- **Additional Codes**: This <a href=\"https://github.com/singsang2/dsc-mod-4-project-v2-1-onl01-dtsc-ft-070620/tree/master/src\">folder</a> contains any other codes that were used for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this project is to build a model that could flag the company when particular product is mentioned in Twitter with negative sentiments for a quick respond to them.\n",
    "\n",
    "So the model will prioritize:\n",
    "\n",
    "    [1] Flagging negative sentiment recall\n",
    "    \n",
    "    [2] Accurately identify product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T20:41:37.831604Z",
     "start_time": "2020-11-10T20:41:37.828841Z"
    }
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given Data:\n",
    "- The dataset comes from CrowdFlower via data.world. Human raters rated the sentiment in over 9,000 Tweets as positive, negative, or neither.\n",
    "\n",
    "Additional Data:\n",
    "- Additional datasets that contain electronic reviews from Amazon and Best Buy from Kaggle were used as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following methods were used to prepare our binary classification text data:\n",
    "\n",
    "    [1] NLTK - TF-IDF vectorizer\n",
    "    [2] spaCy - TF-IDF vectorizer\n",
    "    [3] spaCy - word2vec word embedding.\n",
    "    \n",
    "Then either `MultinomialNB` or `LogisticRegression` were used to train the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T22:44:31.562420Z",
     "start_time": "2020-11-10T22:44:31.546279Z"
    }
   },
   "source": [
    "The following methods were used to prepare our multiclass classification text data:\n",
    "\n",
    "    [1] spaCy - TF-IDF vectorizer\n",
    "    [2] TextBlob - sentiment analyzer\n",
    "    [3] spaCy - word2vec word embedding.\n",
    "    [4] Added additional datasets from Amazon and Best Buy\n",
    "    \n",
    "Then either `MultinomialNB` or `LogisticRegression` were used to train the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model was using `MulticlassNB` with spaCy's word embedding.\n",
    "\n",
    "<img src='images/binary_word_emb.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall Test Accuracy: 81%\n",
    "\n",
    "- Overall Test Recall (weighted): 81%\n",
    "\n",
    "- Negative Sentiment Recall: 76%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T22:53:41.453546Z",
     "start_time": "2020-11-10T22:53:41.449679Z"
    }
   },
   "source": [
    "The best model was using MulticlassNB with spaCy's word embedding.\n",
    "\n",
    "<img src='images/multi_word_emb.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall Test Accuracy: 60%\n",
    "\n",
    "- Overall Test Recall (weighted): 60%\n",
    "\n",
    "- Negative Sentiment Recall: you 71%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Futher data aquisition:\n",
    "- Due to imbalance in data, our model suffered. Acquiring similar datasets with more balanced classes would increase our model's performance and reliability.\n",
    "\n",
    "[2] `Neutral` sentiment:\n",
    "- There are no true `neutral` sentiments for every statement contains certain aspect of bias toward or against something. We believe that binary sentiment with some sort of confidence score in either sentiment would work better than having multiclass sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
