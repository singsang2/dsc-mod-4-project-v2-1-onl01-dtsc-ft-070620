{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Repository Contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T20:33:42.170513Z",
     "start_time": "2020-11-10T20:33:42.166583Z"
    }
   },
   "source": [
    "- **Jupyter Notebook**: This notebook, <a href=\"https://github.com/singsang2/dsc-mod-4-project-v2-1-onl01-dtsc-ft-070620/blob/master/Tweet_sentiment_analysis.ipynb\">Tweet_sentiment_analysis.ipynb</a>, has Twitter sentiment analysis.\n",
    "\n",
    "- **Presentation**: This <a href=\"https://github.com/singsang2/dsc-mod-4-project-v2-1-onl01-dtsc-ft-070620/blob/master/Tweet_sentiment_analysis.pptx\">presentation</a> contains an \"Executive Summary\" that gives a brief overview of your problem/dataset, and each step of the data science process.\n",
    "\n",
    "- **Datasets**: This <a href=\"https://github.com/singsang2/dsc-mod-4-project-v2-1-onl01-dtsc-ft-070620/tree/master/datasets\">folder</a> contains all the datasets used in this project.\n",
    "\n",
    "- **Models**: This <a href=\"https://github.com/singsang2/dsc-mod-4-project-v2-1-onl01-dtsc-ft-070620/tree/master/models\">folder</a> contains all the models trained and used in this project.\n",
    "\n",
    "- **Additional Codes**: This <a href=\"https://github.com/singsang2/dsc-mod-4-project-v2-1-onl01-dtsc-ft-070620/tree/master/src\">folder</a> contains any other codes that were used for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T23:03:42.492284Z",
     "start_time": "2020-11-10T23:03:42.488927Z"
    }
   },
   "source": [
    "<img src='images/wordcloud_pos_neg.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    *Major vocabularies used in positive sentiments and negative sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consumers' voices are getting much attention by big companies not only because their opnions matter, but also their reach of their voice is expanding due to growth of social media platforms such as Facebook, Instagram and Twitter. Thus, it is imperative to monitor and analyze how consumers are responding to one's product not only for customer service purpose, but also to analyze their trends.\n",
    "\n",
    "In this project, we will deal with a portion of what we have mentioned above. We will focus on identifying negative sentiments of Google, Apple and Android products from Twitter data.\n",
    "\n",
    "### Goals\n",
    "The goal of this project is to produce a model that can efficiently\n",
    "\n",
    "[1] identify tweets with negative sentiments towards a product (ex. Apple, Google, or Android products), and\n",
    "-  By identifying negative tweets, a company can provide relatively quick feedback to the customers which will improve brand's image and credibility.\n",
    "        \n",
    "[2] correctly categorize tweets into negative, neutral and positive sentiments.\n",
    "- By cumulating various sentiments about a company's various products, a company could read and predict people's trend.\n",
    "\n",
    "[Extra] We will also train a model that can identify which product a tweet is mentioning.\n",
    "- A company/brand usually has more than just one product (ex. Apple), so by correctly identifying which product tweets are mentioning, it will be more beneficial to the company be aware of their products review by people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T20:41:37.831604Z",
     "start_time": "2020-11-10T20:41:37.828841Z"
    }
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " [1]. The main dataset comes from CrowdFlower via data.world. <a href=\"https://data.world/crowdflower/brands-and-product-emotions\">Data Link</a>\n",
    "\n",
    " [2]. Amazon and Best Buy electronics review dataset. <a href=\"https://www.kaggle.com/datafiniti/amazon-and-best-buy-electronics\">Data Link</a>\n",
    "\n",
    " [3]. Amazon electronics review dataset: <a href=\"https://www.kaggle.com/datafiniti/consumer-reviews-of-amazon-products\">Data Link</a>\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following methods were used to prepare our binary classification text data:\n",
    "\n",
    "    [1] NLTK - TF-IDF vectorizer\n",
    "    [2] spaCy - TF-IDF vectorizer\n",
    "    [3] spaCy - word2vec word embedding.\n",
    "    \n",
    "Then either `MultinomialNB` or `LogisticRegression` were used to train the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T22:44:31.562420Z",
     "start_time": "2020-11-10T22:44:31.546279Z"
    }
   },
   "source": [
    "The following methods were used to prepare our multiclass classification text data:\n",
    "\n",
    "    [1] spaCy - TF-IDF vectorizer\n",
    "    [2] TextBlob - sentiment analyzer\n",
    "    [3] spaCy - word2vec word embedding.\n",
    "    [4] Added additional datasets from Amazon and Best Buy\n",
    "    \n",
    "Then either `MultinomialNB` or `LogisticRegression` were used to train the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-12T19:41:41.992767Z",
     "start_time": "2020-11-12T19:41:41.979758Z"
    }
   },
   "source": [
    "The following table shows the top 5 model that performed for binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/binary_model_report.png' width='700'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression model using word embedding did the best in terms for negative recalls; however it does have a longer average time to fit and predict the result signifcantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/computing_time.png' width='500'> <img src='images/negative_recalls.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model was using `MulticlassNB` with spaCy's word embedding.\n",
    "\n",
    "<img src='images/binary_word_emb.png' width='500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall Test Accuracy: 81%\n",
    "\n",
    "- Overall Test Recall (weighted): 81%\n",
    "\n",
    "- Negative Sentiment Recall: 74%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T22:53:41.453546Z",
     "start_time": "2020-11-10T22:53:41.449679Z"
    }
   },
   "source": [
    "The best model was using MulticlassNB with spaCy's word embedding.\n",
    "\n",
    "<img src='images/multi_word_emb.png' width='500'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall Test Accuracy: 60%\n",
    "\n",
    "- Overall Test Recall (weighted): 60%\n",
    "\n",
    "- Negative Sentiment Recall: you 71%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final models can\n",
    "\n",
    "    [1] Binary Sentiment\n",
    "        * Most 81% accuracy with 76% negative sentiment recall\n",
    "    [2] Multiclass Sentiment\n",
    "        * 60% accuracy with 71% negative sentiment recall \n",
    "    [EXTRA] Product Predictor\n",
    "        * 91% of accuracy\n",
    "\n",
    "## Recommendations\n",
    "We would recommend the following:\n",
    "\n",
    "[1] **Use binary sentiments (positive and negative)**\n",
    "   - Multiclass not only complicates the model itself, but also it dilutes negative and positive sentiments together, therefore, we recommend using binary sentiment classification model\n",
    "    \n",
    "[2] **For the best negative recall model:** *logistic regression word-embedding model*\n",
    "   - this is the best model to flag negative sentiments but it does take some time to train; however, as long as the train is well-done, implementing the model should not cause significant calculation cost. (Further study should be done)\n",
    "\n",
    "[3] **For the fastest computing model:** *Naive Bayes' TF-IDF model with SMOTE*\n",
    "   - this model also did a great job in identifying negative sentiments, but it uses SMOTE which is not recommended in NLP analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Further data acquisition:\n",
    "Due to imbalance in data, our model suffered. Acquiring similar datasets with more balanced classes would increase our model's performance and reliability.\n",
    "\n",
    "[2] Real time Twitter analysis\n",
    "Have this model refined and put in a production so that it can monitor tweets real time and analyze and negative flags about any particular product.\n",
    "\n",
    "[3] Research various costs between models\n",
    "Different models have different strengths and weaknesses, and we believe researching different costs including computing and labor costs using different models would allow us to choose a better model\n",
    "\n",
    "[4] Try different NLP techniques\n",
    "There are so many different NLP techniques and they are growing due to works of so many different research entities. It would be very valuable to try different approach including skip-gram and even deep learning NLP for this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
